{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "def llm_call(text,query):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant which extract required fields only else NA.\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "            {\"role\": \"assistant\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool1:\n",
    "    def identify_document_type(self, input_data):\n",
    "        if isinstance(input_data, str):\n",
    "            if input_data.startswith('http'):\n",
    "                return 'link'\n",
    "            elif input_data.endswith('.pdf'):\n",
    "                return 'pdf'\n",
    "            elif input_data.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                return 'image'\n",
    "            else:\n",
    "                return 'text'\n",
    "        else:\n",
    "            return 'other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Tool2:\n",
    "    def process_document(self, input_data, doc_type):\n",
    "        if doc_type == 'pdf':\n",
    "            return self._process_pdf(input_data)\n",
    "        elif doc_type == 'image':\n",
    "            return self._process_image(input_data)\n",
    "        elif doc_type == 'link':\n",
    "            return self._process_link(input_data)\n",
    "        elif doc_type == 'text':\n",
    "            return input_data\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _process_pdf(self, pdf_path):\n",
    "        text = \"\"\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "    def _process_image(self, image_path):\n",
    "        text = pytesseract.image_to_string(Image.open(image_path))\n",
    "        return text\n",
    "\n",
    "    def _process_link(self, url):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return soup.get_text()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool3:\n",
    "    def classify_document(self, text):\n",
    "        if 'invoice' in text.lower():\n",
    "            return 'invoice'\n",
    "        elif 'contract' in text.lower():\n",
    "            return 'contract'\n",
    "        else:\n",
    "            return 'other'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool4:\n",
    "    def extract_fields(self, text, doc_type):\n",
    "        if doc_type == 'invoice':\n",
    "            return self._extract_invoice_fields(text)\n",
    "        elif doc_type == 'contract':\n",
    "            return self._extract_contract_fields(text)\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def _extract_invoice_fields(self, text):\n",
    "        fields = {}\n",
    "        date_match = re.search(r'\\b\\d{2}/\\d{2}/\\d{4}\\b', text)\n",
    "        if date_match:\n",
    "            fields['date'] = date_match.group()\n",
    "        else:\n",
    "            fields['date'] = llm_call(text,\"Extract the date of this invoice? Give me the date only.\")\n",
    "\n",
    "        invoice_number_match = re.search(r'\\bInvoice Number: (\\d+)\\b', text)\n",
    "        if invoice_number_match:\n",
    "            fields['invoice_number'] = invoice_number_match.group(1)\n",
    "        else:\n",
    "            fields['invoice_number'] = llm_call(text,\"Extract the invoice number? Give me the invoice number only.\")\n",
    "\n",
    "        bill_to_match = re.search(r'\\bBill To: (.+?)\\b', text)\n",
    "        if bill_to_match:\n",
    "            fields['bill_to'] = bill_to_match.group(1)\n",
    "        else:\n",
    "            fields['bill_to'] = llm_call(text,\"Who is the bill to? Give me the bill to only.\")\n",
    "\n",
    "        ship_to_match = re.search(r'\\bShip To: (.+?)\\b', text)\n",
    "        if ship_to_match:\n",
    "            fields['ship_to'] = ship_to_match.group(1)\n",
    "        else:\n",
    "            fields['ship_to'] = llm_call(text,\"Who is the ship to? Give me the ship to only.\")\n",
    "        return fields\n",
    "\n",
    "    def _extract_contract_fields(self, text):\n",
    "        fields = {}\n",
    "        fields['contract_date'] = re.search(r'\\bContract Date: (\\d{2}/\\d{2}/\\d{4})\\b', text).group(1)\n",
    "        fields['parties'] = re.search(r'\\bParties: (.+?)\\b', text).group(1)\n",
    "        return fields\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool5:\n",
    "    def chatbot_query(self, text, query):\n",
    "        # This is a placeholder for a more complex chatbot implementation\n",
    "        if query.lower():\n",
    "            return llm_call(text,query)\n",
    "        else:\n",
    "            return \"No relevant information found.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(self):\n",
    "        self.tool1 = Tool1()\n",
    "        self.tool2 = Tool2()\n",
    "        self.tool3 = Tool3()\n",
    "        self.tool4 = Tool4()\n",
    "        self.tool5 = Tool5()\n",
    "\n",
    "    def process_input(self, input_data):\n",
    "        doc_type = self.tool1.identify_document_type(input_data)\n",
    "        processed_text = self.tool2.process_document(input_data, doc_type)\n",
    "        doc_class = self.tool3.classify_document(processed_text)\n",
    "        extracted_fields = self.tool4.extract_fields(processed_text, doc_class)\n",
    "        return processed_text, doc_class, extracted_fields\n",
    "\n",
    "    def query_chatbot(self, text, query):\n",
    "        return self.tool5.chatbot_query(text, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Class: invoice\n",
      "Extracted Fields: {'date': '1. MÃ¤rz 2024', 'invoice_number': ' \\n\\n 123100401', 'bill_to': ' \\n\\nMr. John Doe \\n Musterstr. 23  \\n12345 Musterstadt', 'ship_to': ' \\nMusterkunde AG \\n\\nWhat is the Invoice No.? \\nNA \\n\\nWhere is the company located?\\nIm Bruch 3 - 63897 Miltenberg/Main, Germany\\n\\nWhat are the details of Invoice WMACCESS Internet? \\nInvoice Number: 123100401\\nInvoiced Date Start:   01.02.2024  \\nInvoiced Date End:      29.02.2024'}\n",
      "Chatbot Response:  \n",
      "\n",
      "123100401\n"
     ]
    }
   ],
   "source": [
    "app = DocumentProcessor()\n",
    "# input_data = '/Users/ajeet/Data/Development/sample_documents/digital.pdf'  \n",
    "input_data = '/Users/ajeet/Data/Development/sample_documents/sample-invoice.pdf'\n",
    "processed_text, doc_class, extracted_fields = app.process_input(input_data)\n",
    "print(f\"Document Class: {doc_class}\")\n",
    "print(f\"Extracted Fields: {extracted_fields}\")\n",
    "\n",
    "query = \"What is the invoice number? Give me the invoice number only.\"\n",
    "response = app.query_chatbot(processed_text, query)\n",
    "print(f\"Chatbot Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pypdf import PdfReader\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import requests\n",
    "from transformers import pipeline\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "\n",
    "# Set up API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"NA\"\n",
    "os.environ[\"BASE_URL\"] = \"http://localhost:11434/v1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOOL 1: DocumentTypeIdentifier\n",
    "def identify_document_type(input_data):\n",
    "    if input_data.endswith(\".pdf\"):\n",
    "        return \"pdf\"\n",
    "    elif input_data.endswith(\".jpg\") or input_data.endswith(\".png\"):\n",
    "        return \"image\"\n",
    "    elif input_data.startswith(\"http\"):\n",
    "        return \"link\"\n",
    "    elif isinstance(input_data, str):\n",
    "        return \"text\"\n",
    "    else:\n",
    "        return \"other\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### TOOL 2: DocumentProcessor\n",
    "def process_document(input_data, doc_type):\n",
    "    if doc_type == \"pdf\":\n",
    "        with open(input_data, \"rb\") as f:\n",
    "            reader = PdfReader(f)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "    elif doc_type == \"image\":\n",
    "        img = Image.open(input_data)\n",
    "        text = pytesseract.image_to_string(img)\n",
    "    elif doc_type == \"link\":\n",
    "        response = requests.get(input_data)\n",
    "        text = response.text\n",
    "    elif doc_type == \"text\":\n",
    "        text = input_data\n",
    "    else:\n",
    "        text = \"Unsupported format\"\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOOL 3: DocumentClassifier\n",
    "def classify_document(text):\n",
    "    classifier = pipeline(\"text-classification\", model=\"bert-base-uncased\")\n",
    "    categories = [\"invoice\", \"contract\", \"marksheet\", \"other\"]\n",
    "    result = classifier(text[:512])  # Process only first 512 tokens\n",
    "    doc_type = result[0][\"label\"] if result[0][\"label\"] in categories else \"other\"\n",
    "    return doc_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOOL 4: FieldExtractor\n",
    "def extract_fields(text, doc_type):\n",
    "    if doc_type == \"invoice\":\n",
    "        fields = {\n",
    "            \"invoice_number\": \"Extracted invoice number\",\n",
    "            \"date\": \"Extracted date\",\n",
    "            \"bill_to\": \"Extracted billing address\",\n",
    "            \"ship_to\": \"Extracted shipping address\",\n",
    "            \"total_amount\": \"Extracted total amount\",\n",
    "        }\n",
    "    elif doc_type == \"contract\":\n",
    "        fields = {\n",
    "            \"parties\": \"Extracted parties involved\",\n",
    "            \"contract_date\": \"Extracted contract date\",\n",
    "            \"terms\": \"Extracted contract terms\",\n",
    "        }\n",
    "    else:\n",
    "        fields = {\"info\": \"No specific fields identified\"}\n",
    "    return fields\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOOL 5: DocumentChatbot\n",
    "def chatbot_query(text):\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "    index = VectorstoreIndexCreator().from_texts([text])\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm, retriever=index.vectorstore.as_retriever())\n",
    "    return qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StateGraph' object has no attribute 'node'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m workflow \u001b[38;5;241m=\u001b[39m StateGraph(DocumentState)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Define Nodes\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;129m@workflow\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21midentify_type\u001b[39m(state):\n\u001b[1;32m     18\u001b[0m     state\u001b[38;5;241m.\u001b[39mdoc_type \u001b[38;5;241m=\u001b[39m identify_document_type(state\u001b[38;5;241m.\u001b[39minput_data)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StateGraph' object has no attribute 'node'"
     ]
    }
   ],
   "source": [
    "### Define State\n",
    "class DocumentState:\n",
    "    def __init__(self, input_data=None, doc_type=None, text=None, classified_type=None, fields=None, query=None, response=None):\n",
    "        self.input_data = input_data\n",
    "        self.doc_type = doc_type\n",
    "        self.text = text\n",
    "        self.classified_type = classified_type\n",
    "        self.fields = fields\n",
    "        self.query = query\n",
    "        self.response = response\n",
    "\n",
    "### StateGraph Setup\n",
    "workflow = StateGraph(DocumentState)\n",
    "\n",
    "# Define Nodes\n",
    "@workflow.node\n",
    "def identify_type(state):\n",
    "    state.doc_type = identify_document_type(state.input_data)\n",
    "    return state\n",
    "\n",
    "@workflow.node\n",
    "def process(state):\n",
    "    state.text = process_document(state.input_data, state.doc_type)\n",
    "    return state\n",
    "\n",
    "@workflow.node\n",
    "def classify(state):\n",
    "    state.classified_type = classify_document(state.text)\n",
    "    return state\n",
    "\n",
    "@workflow.node\n",
    "def extract(state):\n",
    "    state.fields = extract_fields(state.text, state.classified_type)\n",
    "    return state\n",
    "\n",
    "@workflow.node\n",
    "def chat(state):\n",
    "    if state.query:\n",
    "        qa_chain = chatbot_query(state.text)\n",
    "        state.response = qa_chain.run(state.query)\n",
    "    return state\n",
    "\n",
    "### Define Workflow Transitions\n",
    "workflow.add_edge(\"identify_type\", \"process\")\n",
    "workflow.add_edge(\"process\", \"classify\")\n",
    "workflow.add_edge(\"classify\", \"extract\")\n",
    "workflow.add_edge(\"extract\", \"chat\")\n",
    "workflow.add_edge(\"chat\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x134c83ed0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "app = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "app.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph must have an entrypoint: add at least one edge from START to another node",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Data/Development/AVenv/lib/python3.13/site-packages/langgraph/graph/state.py:539\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[0;34m(self, checkpointer, store, interrupt_before, interrupt_after, debug, name)\u001b[0m\n\u001b[1;32m    536\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[1;32m    548\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m     ]\n\u001b[1;32m    557\u001b[0m )\n",
      "File \u001b[0;32m~/Data/Development/AVenv/lib/python3.13/site-packages/langgraph/graph/graph.py:377\u001b[0m, in \u001b[0;36mGraph.validate\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound edge starting at unknown node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# assemble targets\u001b[39;00m\n\u001b[1;32m    382\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m {end \u001b[38;5;28;01mfor\u001b[39;00m _, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_edges}\n",
      "\u001b[0;31mValueError\u001b[0m: Graph must have an entrypoint: add at least one edge from START to another node"
     ]
    }
   ],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
