{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This module defines a function to create a state graph for an agent-based workflow and compile it into a runnable workflow.\n",
    "Functions:\n",
    "    create_graph(server=None, model=None, stop=None, model_endpoint=None, temperature=0):\n",
    "        Creates a StateGraph with various agents and tools as nodes, and defines the edges between them.\n",
    "        Parameters:\n",
    "            server (optional): The server to be used by the agents.\n",
    "            model (optional): The model to be used by the agents.\n",
    "            stop (optional): The stop condition for the agents.\n",
    "            model_endpoint (optional): The endpoint for the model.\n",
    "            temperature (optional): The temperature setting for the model.\n",
    "        Returns:\n",
    "            StateGraph: The constructed state graph with nodes and edges.\n",
    "    compile_workflow(graph):\n",
    "        Compiles the given state graph into a runnable workflow.\n",
    "        Parameters:\n",
    "            graph (StateGraph): The state graph to be compiled.\n",
    "        Returns:\n",
    "            The compiled workflow.\n",
    "\"\"\"\n",
    "import json\n",
    "import ast\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import HumanMessage\n",
    "from models.openai_models import get_open_ai_json\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from agents.agents import (\n",
    "    PlannerAgent,\n",
    "    SelectorAgent,\n",
    "    ReporterAgent,\n",
    "    ReviewerAgent,\n",
    "    RouterAgent,\n",
    "    FinalReportAgent,\n",
    "    EndNodeAgent\n",
    ")\n",
    "from prompts.prompts import (\n",
    "    reviewer_prompt_template, \n",
    "    planner_prompt_template, \n",
    "    selector_prompt_template, \n",
    "    reporter_prompt_template,\n",
    "    router_prompt_template,\n",
    "    reviewer_guided_json,\n",
    "    selector_guided_json,\n",
    "    planner_guided_json,\n",
    "    router_guided_json\n",
    "\n",
    ")\n",
    "from tools.google_serper import get_google_serper\n",
    "from tools.basic_scraper import scrape_website\n",
    "from states.state import AgentGraphState, get_agent_graph_state, state\n",
    "\n",
    "def create_graph(server=None, model=None, stop=None, model_endpoint=None, temperature=0):\n",
    "    graph = StateGraph(AgentGraphState)\n",
    "\n",
    "    graph.add_node(\n",
    "        \"planner\", \n",
    "        lambda state: PlannerAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=planner_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_latest\"),\n",
    "            # previous_plans=lambda: get_agent_graph_state(state=state, state_key=\"planner_all\"),\n",
    "            prompt=planner_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"selector\",\n",
    "        lambda state: SelectorAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=selector_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_latest\"),\n",
    "            previous_selections=lambda: get_agent_graph_state(state=state, state_key=\"selector_all\"),\n",
    "            serp=lambda: get_agent_graph_state(state=state, state_key=\"serper_latest\"),\n",
    "            prompt=selector_prompt_template,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"reporter\", \n",
    "        lambda state: ReporterAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_latest\"),\n",
    "            previous_reports=lambda: get_agent_graph_state(state=state, state_key=\"reporter_all\"),\n",
    "            research=lambda: get_agent_graph_state(state=state, state_key=\"scraper_latest\"),\n",
    "            prompt=reporter_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"reviewer\", \n",
    "        lambda state: ReviewerAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=reviewer_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_all\"),\n",
    "            # planner=lambda: get_agent_graph_state(state=state, state_key=\"planner_latest\"),\n",
    "            # selector=lambda: get_agent_graph_state(state=state, state_key=\"selector_latest\"),\n",
    "            reporter=lambda: get_agent_graph_state(state=state, state_key=\"reporter_latest\"),\n",
    "            # planner_agent=planner_prompt_template,\n",
    "            # selector_agent=selector_prompt_template,\n",
    "            # reporter_agent=reporter_prompt_template,\n",
    "            # serp=lambda: get_agent_graph_state(state=state, state_key=\"serper_latest\"),\n",
    "            prompt=reviewer_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"router\", \n",
    "        lambda state: RouterAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=router_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_all\"),\n",
    "            # planner=lambda: get_agent_graph_state(state=state, state_key=\"planner_latest\"),\n",
    "            # selector=lambda: get_agent_graph_state(state=state, state_key=\"selector_latest\"),\n",
    "            # reporter=lambda: get_agent_graph_state(state=state, state_key=\"reporter_latest\"),\n",
    "            # planner_agent=planner_prompt_template,\n",
    "            # selector_agent=selector_prompt_template,\n",
    "            # reporter_agent=reporter_prompt_template,\n",
    "            # serp=lambda: get_agent_graph_state(state=state, state_key=\"serper_latest\"),\n",
    "            prompt=router_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    graph.add_node(\n",
    "        \"serper_tool\",\n",
    "        lambda state: get_google_serper(\n",
    "            state=state,\n",
    "            plan=lambda: get_agent_graph_state(state=state, state_key=\"planner_latest\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"scraper_tool\",\n",
    "        lambda state: scrape_website(\n",
    "            state=state,\n",
    "            research=lambda: get_agent_graph_state(state=state, state_key=\"selector_latest\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"final_report\", \n",
    "        lambda state: FinalReportAgent(\n",
    "            state=state\n",
    "        ).invoke(\n",
    "            final_response=lambda: get_agent_graph_state(state=state, state_key=\"reporter_latest\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\"end\", lambda state: EndNodeAgent(state).invoke())\n",
    "\n",
    "    # Define the edges in the agent graph\n",
    "    def pass_review(state: AgentGraphState):\n",
    "        review_list = state[\"router_response\"]\n",
    "        if review_list:\n",
    "            review = review_list[-1]\n",
    "        else:\n",
    "            review = \"No review\"\n",
    "\n",
    "        if review != \"No review\":\n",
    "            if isinstance(review, HumanMessage):\n",
    "                review_content = review.content\n",
    "            else:\n",
    "                review_content = review\n",
    "            \n",
    "            review_data = json.loads(review_content)\n",
    "            next_agent = review_data[\"next_agent\"]\n",
    "        else:\n",
    "            next_agent = \"end\"\n",
    "\n",
    "        return next_agent\n",
    "\n",
    "    # Add edges to the graph\n",
    "    graph.set_entry_point(\"planner\")\n",
    "    graph.set_finish_point(\"end\")\n",
    "    graph.add_edge(\"planner\", \"serper_tool\")\n",
    "    graph.add_edge(\"serper_tool\", \"selector\")\n",
    "    graph.add_edge(\"selector\", \"scraper_tool\")\n",
    "    graph.add_edge(\"scraper_tool\", \"reporter\")\n",
    "    graph.add_edge(\"reporter\", \"reviewer\")\n",
    "    graph.add_edge(\"reviewer\", \"router\")\n",
    "\n",
    "    graph.add_conditional_edges(\n",
    "        \"router\",\n",
    "        lambda state: pass_review(state=state),\n",
    "    )\n",
    "\n",
    "    graph.add_edge(\"final_report\", \"end\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "def compile_workflow(graph):\n",
    "    workflow = graph.compile()\n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated # used for type hinting with metadata\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults # used for search tool\n",
    "from langchain_community.tools.google_search import GoogleSearchResults # used for search tool\n",
    "from langchain_core.messages import BaseMessage \n",
    "from typing_extensions import TypedDict\n",
    "# from langchain_community.tools.web_scraper import WebScraperResults # used for web scraping tool\n",
    "# from langchain_community.tools.\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for GoogleSearchResults\napi_wrapper\n  Field required [type=missing, input_value={'max_results': 2}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m graph_builder \u001b[38;5;241m=\u001b[39m StateGraph(State)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# tool = TavilySearchResults(max_results=2)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m tool \u001b[38;5;241m=\u001b[39m \u001b[43mGoogleSearchResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# search tool\u001b[39;00m\n\u001b[1;32m     11\u001b[0m tools \u001b[38;5;241m=\u001b[39m [tool]\n\u001b[1;32m     12\u001b[0m llm \u001b[38;5;241m=\u001b[39m  ChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4o\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     emit_warning()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:432\u001b[0m, in \u001b[0;36mBaseTool.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs_schema must be a subclass of pydantic BaseModel. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs_schema\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 432\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for GoogleSearchResults\napi_wrapper\n  Field required [type=missing, input_value={'max_results': 2}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    '''State for the state graph'''\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Create the state graph \n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# tool = TavilySearchResults(max_results=2)\n",
    "tool = GoogleSearchResults(max_results=2) # search tool\n",
    "tools = [tool]\n",
    "llm =  ChatOpenAI(model=\"4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the OpenAI API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "# print(openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# For this ipynb we set parallel tool calling to false as math generally is done sequentially, and this time we have 3 tools that can do math\n",
    "# the OpenAI model specifically defaults to parallel tool calling for efficiency, see https://python.langchain.com/docs/how_to/tool_calling_parallel/\n",
    "# play around with it and see how the model behaves with math equations!\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant) # assistant is a node that uses the assistant function\n",
    "builder.add_node(\"tools\", ToolNode(tools)) # tools is a node that uses the ToolNode class with the tools list\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"process for given list [{operation:'take 2 and 3 add it and multiply its result with 5'},{operation:'take 4 and 6 add it and multiply its result with 10'},{operation:'take 121 and 3 add it and divide its result with 2'}]. I want the result in the form of list of dictionary\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "process for given list [{operation:'take 2 and 3 add it and multiply its result with 5'},{operation:'take 4 and 6 add it and multiply its result with 10'},{operation:'take 121 and 3 add it and divide its result with 2'}]. I want the result in the form of list of dictionary\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_quCADuLcciHG6saajb7VAprD)\n",
      " Call ID: call_quCADuLcciHG6saajb7VAprD\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_3FV4lkU0QXDhuRCBz4OLoJf1)\n",
      " Call ID: call_3FV4lkU0QXDhuRCBz4OLoJf1\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "25\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_Z8kcy2SnkWhIYJJk5UaRrdNg)\n",
      " Call ID: call_Z8kcy2SnkWhIYJJk5UaRrdNg\n",
      "  Args:\n",
      "    a: 4\n",
      "    b: 6\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "10\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_BZNH01PA76CrzmgIe7XBh4os)\n",
      " Call ID: call_BZNH01PA76CrzmgIe7XBh4os\n",
      "  Args:\n",
      "    a: 10\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "100\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_HAQj6uePeOTTmhp3QRV6bdlK)\n",
      " Call ID: call_HAQj6uePeOTTmhp3QRV6bdlK\n",
      "  Args:\n",
      "    a: 121\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "124\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (call_cfnrEnKGrekfESv6vvf57Ju6)\n",
      " Call ID: call_cfnrEnKGrekfESv6vvf57Ju6\n",
      "  Args:\n",
      "    a: 124\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide\n",
      "\n",
      "62.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are the results for each operation:\n",
      "\n",
      "1. For the operation \"take 2 and 3 add it and multiply its result with 5\":\n",
      "   - Result: 25\n",
      "\n",
      "2. For the operation \"take 4 and 6 add it and multiply its result with 10\":\n",
      "   - Result: 100\n",
      "\n",
      "3. For the operation \"take 121 and 3 add it and divide its result with 2\":\n",
      "   - Result: 62.0\n",
      "\n",
      "Returning the results as a list of dictionaries:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\"result\": 25},\n",
      "  {\"result\": 100},\n",
      "  {\"result\": 62.0}\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design websearch and scrapping tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googlesearch-python\n",
      "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in /home/scientificspace/.venv/lib/python3.12/site-packages (from googlesearch-python) (4.12.3)\n",
      "Requirement already satisfied: requests>=2.20 in /home/scientificspace/.venv/lib/python3.12/site-packages (from googlesearch-python) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/scientificspace/.venv/lib/python3.12/site-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/scientificspace/.venv/lib/python3.12/site-packages (from requests>=2.20->googlesearch-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/scientificspace/.venv/lib/python3.12/site-packages (from requests>=2.20->googlesearch-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/scientificspace/.venv/lib/python3.12/site-packages (from requests>=2.20->googlesearch-python) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/scientificspace/.venv/lib/python3.12/site-packages (from requests>=2.20->googlesearch-python) (2024.12.14)\n",
      "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
      "Installing collected packages: googlesearch-python\n",
      "Successfully installed googlesearch-python-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googlesearch-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "result = search(\"Google\", advanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.co.in/\n",
      "https://www.google.com/\n",
      "https://twitter.com/Google?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor\n",
      "https://www.google.co.in/\n",
      "https://about.google/\n",
      "https://cloud.google.com/\n",
      "https://search.google.com/search-console/about\n",
      "https://play.google.com/store/apps/details?id=com.google.android.googlequicksearchbox&hl=en_IN\n",
      "https://www.google.com/account/about/\n",
      "https://myactivity.google.com/\n"
     ]
    }
   ],
   "source": [
    "for i in result:\n",
    "    print(i.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.path.abspath('.')\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"HCL Technologies\"\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(f\"Extract the topic only from given query. Query: 'write a blog on hcl technologies.'\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "\n",
    "class GenAI:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(\n",
    "        base_url = 'http://localhost:11434/v1',\n",
    "        api_key='ollama', # required, but unused\n",
    "        )\n",
    "\n",
    "\n",
    "    def blog_generate(self, topic, context):\n",
    "        ''' \n",
    "        It generates a blog post based on the given topic and context based on the tone\n",
    "        '''\n",
    "        completion = self.client.chat.completions.create(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"\n",
    "You are an AI assistant. Your task is to generate a detailed blog post in simplified language. \n",
    "The blog should be easy to understand, engaging, and informative. \n",
    "Make sure to break down complex concepts into simpler terms and provide examples where necessary.\n",
    "\"\"\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\"\"\n",
    "Write a blog post on the topic: {topic}. \n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Make sure the blog post is detailed, easy to understand, and engaging. Break down complex concepts into simpler terms and provide examples where necessary. \n",
    "\"\"\".format(topic=topic, context=context),\n",
    "            }\n",
    "            ],\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import sys,os\n",
    "# sys.path.insert(0, os.path.abspath('./src'),\"..\")\n",
    "# from src.modules.genai import GenAI\n",
    "from googlesearch import search\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def validate_url(url: str) -> bool:\n",
    "    \"\"\"Validate the url.\n",
    "\n",
    "    Args:\n",
    "        url: The website url.\n",
    "    \"\"\"\n",
    "    # Regular expression for validating a URL\n",
    "    regex = re.compile(\n",
    "        r'^(?:http|ftp)s?://'  # http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\n",
    "        r'localhost|'  # localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}|'  # ...or ipv4\n",
    "        r'\\[?[A-F0-9]*:[A-F0-9:]+\\]?)'  # ...or ipv6\n",
    "        r'(?::\\d+)?'  # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "\n",
    "    if re.match(regex, url) is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def web_search(topic: str) -> list:\n",
    "    \"\"\"Search the web for the query.\n",
    "\n",
    "    Args:\n",
    "        query: The search query.\n",
    "    \"\"\"\n",
    "    results = search(topic, advanced=True)\n",
    "    return [url.url for url in results if validate_url(url.url)][:2]\n",
    "\n",
    "def query_title(query: str) -> str:\n",
    "    \"\"\"Query the title for the query.\n",
    "\n",
    "    Args:\n",
    "        query: The search query.\n",
    "    \"\"\"\n",
    "    return llm.invoke(f\"Extract the topic only from given query. Query: {query}.\").content\n",
    "\n",
    "def web_scrape(url: str) -> str:\n",
    "    \"\"\"Scrape the website for the url.\n",
    "\n",
    "    Args:\n",
    "        url: The website url.\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html5lib') # html5lib parser is used to parse the content\n",
    "    # print(soup.prettify())\n",
    "    # print(soup.get_text())\n",
    "    return soup.get_text()\n",
    "\n",
    "def content_summary (content: str) -> str:\n",
    "    \"\"\"Generate a summary of the websearch.\n",
    "\n",
    "    Args:\n",
    "        content: Content of websearch.\n",
    "    \"\"\"\n",
    "    return llm.invoke(f\"Summarize the content in detail. Content: {content}\").content\n",
    "    \n",
    "def generate_blog(query: str) -> str:\n",
    "    \"\"\"Generate a blog with the title and content if the query is not \n",
    "\n",
    "    Args:\n",
    "        query: Unknown input query for websearch .\n",
    "    \"\"\"\n",
    "    detailed_scrape_summary = \"\"\n",
    "    topic = query_title(query)\n",
    "    print(\"Topic-->\",topic)\n",
    "    url_list = web_search(topic)\n",
    "    for url in url_list:\n",
    "        print(\"URL-->\",url)  \n",
    "        content = web_scrape(url)\n",
    "        content = content_summary(content)\n",
    "        if content:\n",
    "            detailed_scrape_summary += f\"{content}\\n\\n\"\n",
    "    # print(detailed_scrape_summary)\n",
    "    obj = GenAI()\n",
    "    \n",
    "    return obj.blog_generate(topic = topic, context = detailed_scrape_summary)\n",
    "\n",
    "\n",
    "tools = [generate_blog]\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "\n",
    "# For this ipynb we set parallel tool calling to false as math generally is done sequentially, and this time we have 3 tools that can do math\n",
    "# the OpenAI model specifically defaults to parallel tool calling for efficiency, see https://python.langchain.com/docs/how_to/tool_calling_parallel/\n",
    "# play around with it and see how the model behaves with math equations!\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://economictimes.indiatimes.com/hcl-technologies-ltd/stocksupdate/companyid-4291.cms', 'https://www.hcltech.com/newsfeed']\n"
     ]
    }
   ],
   "source": [
    "url_list = web_search(\"Latest updates on HCL Technologies.\")\n",
    "print(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic--> Latest Agentic AI Frameworks\n",
      "URL--> https://lekha-bhan88.medium.com/top-5-agentic-ai-frameworks-to-watch-in-2025-9d51b2b652c0\n",
      "URL--> https://www.ibm.com/think/insights/top-ai-agent-frameworks\n"
     ]
    }
   ],
   "source": [
    "query = \"write a blog on latest agentic ai frameworks.\"\n",
    "blog = generate_blog(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Latest Agentic AI Frameworks: A Guide for Businesses**\n",
      "\n",
      "Artificial intelligence (AI) has become an integral part of modern businesses, transforming the way they operate and interact with customers. Among the numerous AI frameworks available, agentic AI frameworks have emerged as a popular choice for organizations looking to create intelligent systems that can adapt and learn from their environment. In this blog post, we'll explore the latest agantic AI frameworks, their features, and benefits, along with example use cases.\n",
      "\n",
      "**What are Agantic AI Frameworks?**\n",
      "\n",
      "Agantic AI frameworks are designed to enable businesses to build intelligent systems that can learn and adapt in a data-driven world. These frameworks combine elements of both machine learning and ontology-based reasoning to create sophisticated models that can navigate complex decision-making spaces. Unlike traditional rule-based approaches, agentic AI frameworks use algorithms that allow their underlying logic to evolve over time, enabling them to respond more effectively to changing environments.\n",
      "\n",
      "**Types of Agantic AI Frameworks**\n",
      "\n",
      "Several types of agantic AI frameworks have emerged in recent years, including:\n",
      "\n",
      "1. **Hybrid Rule-Based and Machine Learning (HRBM) Framework:** This framework combines the strengths of both rule-based systems and machine learning algorithms to create a hybrid approach.\n",
      "2. **Causal Graph-Constrained Reinforcement Learning (CG-CRL):** This framework provides a graph-constrained reinforcement learning approach, which enables more efficient policy search.\n",
      "\n",
      "Top 5 Agantic AI Frameworks for Businesses\n",
      "\n",
      "Here are some of the top agantic AI frameworks that businesses can consider:\n",
      "\n",
      "1. **Stanford's A2 (Autonomous Agent) Framework:** Developed by Stanford University researchers, this framework uses machine learning and ontology-based reasoning to create intelligent agents.\n",
      "2. **CG-CRL Framework:** This framework provides a graph-constrained reinforcement learning approach, enabling more efficient policy search.\n",
      "3. **A* Framework:** This framework uses autonomous algorithms to solve planning and decision-making problems in complex environments.\n",
      "\n",
      "Benefits of Using Agantic AI Frameworks\n",
      "\n",
      "Agantic AI frameworks offer several benefits for businesses looking to create intelligent systems, including:\n",
      "\n",
      "1. **Improved Decision-Making Accuracy**\n",
      "2. **Increased Agility in Complex Environments**\n",
      "3. **Enhanced Adaptability through Machine Learning**\n",
      "\n",
      "**How to Implement an Agantic AI Framework**\n",
      "\n",
      "Implementing an agantic AI framework requires a careful consideration of the following steps:\n",
      "\n",
      "1. **Define your Environment:** Identify the critical components and actors within your organization.\n",
      "2. **Choose the Right Algorithmic Approach:** Select from a range of algorithms, such as CG-CRL or HRBM.\n",
      "3. **Build Intelligent Models:** Develop machine learning models to navigate these complexities.\n",
      "4. **Test and Refine:** Continuously refine and test your intelligent system for optimal performance.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "Agantic AI frameworks have the potential to revolutionize business decision-making by enabling organizations to build intelligent systems that can adapt and learn in complex environments. By considering their benefits, types, and how to implement them, businesses can unlock significant value from AI technology.\n",
      "\n",
      "\n",
      "**Example Code: Implementing an Agantic AI Framework using Stanford's A2 Framework**\n",
      "\n",
      "```python\n",
      "import rasa\n",
      "\n",
      "# Define the actions and intents for our conversation flow\n",
      "actions = ['greet', 'thankyou', 'quit']\n",
      "intents = {\n",
      "    'greet': ['hello', 'hi'],\n",
      "}\n",
      "\n",
      "# Define the dialogue structure:\n",
      "dialogue_structure = [\n",
      "    {'name': 'start', 'next': 'initial'},\n",
      "]\n",
      "\n",
      "# Create an instance of A2:\n",
      "agent_a2 = rasa.Agent(actions=actions, intents=intents)\n",
      "```\n",
      "\n",
      "This example code snippet demonstrates how to implement an agentic AI framework using Stanford's A2 framework. This provides a solid foundation for businesses looking to create intelligent systems that can adapt and learn from their environment.\n",
      "\n",
      "Remember to keep your code well-structured and readable as it grows in complexity.\n"
     ]
    }
   ],
   "source": [
    "print(blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI assistant. Your task is to generate a detailed blog post in simplified language. \n",
    "The blog must contains title, body and conclusion. It should be easy to understand, engaging, and informative. \n",
    "Make sure to break down complex concepts into simpler terms and provide examples where necessary.\n",
    "\"\"\"\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=SYSTEM_PROMPT)\n",
    "\n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    # return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode([generate_blog]))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import HumanMessage\n",
    "# messages = [HumanMessage(content=\"Agentic AI\")]\n",
    "# messages = graph.invoke({\"messages\": messages})\n",
    "# for m in messages['messages']:\n",
    "#     m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Artifical Intelligence.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Title: Understanding Artificial Intelligence: A Simple Guide**\n",
      "\n",
      "**Body:**\n",
      "\n",
      "Artificial Intelligence, or AI, is a buzzword you've likely heard a lot about. But what exactly is it? Let's break it down in a way that's easy to understand.\n",
      "\n",
      "1. **What is AI?**\n",
      "\n",
      "   AI is like teaching a computer to think and make decisions like a human. Imagine you have a smart friend who can learn from experience, solve problems, and even predict what might happen next. That's what AI does, but with computers.\n",
      "\n",
      "2. **How Does AI Work?**\n",
      "\n",
      "   AI uses something called algorithms, which are like step-by-step instructions, to analyze data and make decisions. Think of it like a recipe that a computer follows to bake a cake. But instead of baking, it might be deciding which movie you might like to watch based on your past choices.\n",
      "\n",
      "3. **Types of AI:**\n",
      "\n",
      "   - **Narrow AI:** This type of AI is designed to do one task really well. For example, the AI in your smartphone that recognizes your voice is a form of Narrow AI.\n",
      "   \n",
      "   - **General AI:** This is a more advanced type that can understand, learn, and apply knowledge in different situations, just like a human. We're not quite there yet, but it's a goal for the future.\n",
      "\n",
      "4. **AI in Everyday Life:**\n",
      "\n",
      "   You might not realize it, but AI is all around you. Here are some examples:\n",
      "\n",
      "   - **Virtual Assistants:** Siri or Alexa are AI-powered assistants that can answer questions and help you manage your tasks.\n",
      "   \n",
      "   - **Recommendation Systems:** Ever wonder how Netflix knows what show you might like? That's AI at work, analyzing your viewing habits and suggesting similar content.\n",
      "   \n",
      "   - **Self-Driving Cars:** These vehicles use AI to navigate roads, avoid obstacles, and drive safely without human input.\n",
      "\n",
      "5. **Benefits and Challenges:**\n",
      "\n",
      "   AI can make our lives easier by handling repetitive tasks, improving healthcare with accurate diagnoses, and even enhancing customer service with chatbots. However, there are challenges too, like privacy concerns and the fear of job loss as machines take over some tasks.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Artificial Intelligence is a fascinating and rapidly growing field that is shaping our world in many ways. By understanding the basics of AI, you can better appreciate the technology that powers so much of our daily lives. As we continue to develop AI, it's important to think about how it can best serve humanity and ensure that its benefits are shared widely. Whether it's through smarter devices, safer streets, or more personalized services, AI has the potential to improve our lives in countless ways.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"Artifical Intelligence.\")]\n",
    "messages = graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is a fascinating and rapidly growing field that is changing the way we live and work. Let's break down what AI is, how it works, and some examples of how it's used today.\n",
      "\n",
      "### What is Artificial Intelligence?\n",
      "\n",
      "Artificial Intelligence refers to computer systems designed to perform tasks that normally require human intelligence. These tasks include understanding language, recognizing patterns, solving problems, and even learning from experience.\n",
      "\n",
      "### How Does AI Work?\n",
      "\n",
      "AI works by using algorithms, which are sets of rules or instructions given to a computer to help it solve problems or perform tasks. There are different types of AI, but two of the most common are:\n",
      "\n",
      "1. **Machine Learning**: This is when computers learn from data. For example, if you show a computer many pictures of cats, it can learn to recognize a cat in new pictures.\n",
      "\n",
      "2. **Deep Learning**: This is a type of machine learning that uses neural networks, which are computer systems modeled after the human brain. Deep learning is especially good at recognizing patterns and making decisions.\n",
      "\n",
      "### Examples of AI in Everyday Life\n",
      "\n",
      "AI is already a big part of our daily lives, even if we don't always realize it. Here are some examples:\n",
      "\n",
      "- **Virtual Assistants**: Devices like Siri, Alexa, and Google Assistant use AI to understand and respond to our questions.\n",
      "  \n",
      "- **Recommendation Systems**: Netflix and YouTube use AI to suggest movies and videos you might like based on what you've watched before.\n",
      "\n",
      "- **Self-Driving Cars**: Companies like Tesla are using AI to develop cars that can drive themselves safely.\n",
      "\n",
      "- **Healthcare**: AI helps doctors to diagnose diseases and develop treatment plans by analyzing medical data.\n",
      "\n",
      "### Why is AI Important?\n",
      "\n",
      "AI is important because it can handle tasks that are too complex for humans or too tedious. It can help businesses run more efficiently, improve healthcare, enhance customer service, and even help to tackle global issues like climate change.\n",
      "\n",
      "### Challenges and Considerations\n",
      "\n",
      "While AI offers many benefits, there are also challenges. These include:\n",
      "\n",
      "- **Ethical Concerns**: Ensuring AI is used responsibly and does not harm people.\n",
      "  \n",
      "- **Job Displacement**: As AI takes over certain tasks, some jobs may become obsolete, requiring people to learn new skills.\n",
      "\n",
      "- **Privacy**: AI systems often need a lot of data to function, which can raise concerns about how our personal information is used and protected.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Artificial Intelligence is a powerful tool that is shaping the future. As it continues to evolve, it's important to consider both its potential and its challenges. By understanding AI, we can better prepare for a world where intelligent machines play a larger role in our lives.\n"
     ]
    }
   ],
   "source": [
    "print(messages['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*, name: str = 'tavily_search', description: str = 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain_tavily.tavily_search.TavilySearchInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain_core.callbacks.base.BaseCallbackManager] = None, tags: Optional[list[str]] = None, metadata: Optional[dict[str, Any]] = None, handle_tool_error: bool = True, handle_validation_error: Union[bool, str, Callable[[Union[pydantic_core._pydantic_core.ValidationError, pydantic.v1.error_wrappers.ValidationError]], str], NoneType] = False, response_format: Literal['content', 'content_and_artifact'] = 'content', include_domains: Optional[List[str]] = None, exclude_domains: Optional[List[str]] = None, search_depth: Optional[Literal['basic', 'advanced']] = 'basic', include_images: Optional[bool] = False, time_range: Optional[Literal['day', 'week', 'month', 'year']] = None, max_results: Optional[int] = 5, topic: Optional[Literal['general', 'news', 'finance']] = 'general', include_answer: Optional[bool] = False, include_raw_content: Optional[bool] = False, include_image_descriptions: Optional[bool] = False, api_wrapper: langchain_tavily._utilities.TavilySearchAPIWrapper = <factory>) -> None\n",
      "Parameter: name\n",
      "Type: <class 'str'>\n",
      "Default: tavily_search\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: description\n",
      "Type: <class 'str'>\n",
      "Default: A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: args_schema\n",
      "Type: typing.Type[pydantic.main.BaseModel]\n",
      "Default: <class 'langchain_tavily.tavily_search.TavilySearchInput'>\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: return_direct\n",
      "Type: <class 'bool'>\n",
      "Default: False\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: verbose\n",
      "Type: <class 'bool'>\n",
      "Default: False\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: callbacks\n",
      "Type: typing.Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType]\n",
      "Default: None\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: callback_manager\n",
      "Type: typing.Optional[langchain_core.callbacks.base.BaseCallbackManager]\n",
      "Default: None\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: tags\n",
      "Type: typing.Optional[list[str]]\n",
      "Default: None\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: metadata\n",
      "Type: typing.Optional[dict[str, typing.Any]]\n",
      "Default: None\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: handle_tool_error\n",
      "Type: <class 'bool'>\n",
      "Default: True\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: handle_validation_error\n",
      "Type: typing.Union[bool, str, typing.Callable[[typing.Union[pydantic_core._pydantic_core.ValidationError, pydantic.v1.error_wrappers.ValidationError]], str], NoneType]\n",
      "Default: False\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: response_format\n",
      "Type: typing.Literal['content', 'content_and_artifact']\n",
      "Default: content\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: include_domains\n",
      "Type: typing.Optional[typing.List[str]]\n",
      "Default: None\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: exclude_domains\n",
      "Type: typing.Optional[typing.List[str]]\n",
      "Default: None\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: search_depth\n",
      "Type: typing.Optional[typing.Literal['basic', 'advanced']]\n",
      "Default: basic\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: include_images\n",
      "Type: typing.Optional[bool]\n",
      "Default: False\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: time_range\n",
      "Type: typing.Optional[typing.Literal['day', 'week', 'month', 'year']]\n",
      "Default: None\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: max_results\n",
      "Type: typing.Optional[int]\n",
      "Default: 5\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: topic\n",
      "Type: typing.Optional[typing.Literal['general', 'news', 'finance']]\n",
      "Default: general\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: include_answer\n",
      "Type: typing.Optional[bool]\n",
      "Default: False\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: include_raw_content\n",
      "Type: typing.Optional[bool]\n",
      "Default: False\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: include_image_descriptions\n",
      "Type: typing.Optional[bool]\n",
      "Default: False\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n",
      "Parameter: api_wrapper\n",
      "Type: <class 'langchain_tavily._utilities.TavilySearchAPIWrapper'>\n",
      "Default: <factory>\n",
      "Kind: KEYWORD_ONLY\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "# retrieve the function's signature\n",
    "sig = inspect.signature(TavilySearch)\n",
    "\n",
    "print(sig)\n",
    "\n",
    "# Access specific parameter details\n",
    "for param in sig.parameters.values():\n",
    "    print(f\"Parameter: {param.name}\")\n",
    "    print(f\"Type: {param.annotation}\")\n",
    "    print(f\"Default: {param.default}\")\n",
    "    print(f\"Kind: {param.kind}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
