{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "# ! pip install langchain-openai\n",
    "# ! pip install -U langchain\n",
    "! pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# from langchain_community.utilities import tesseract\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import SystemMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "import PyPDF2\n",
    "from pdfminer.high_level import extract_text as pdfminer_extract_text\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 1. Document Loading\n",
    "# ------------------------------------------------------------------------------\n",
    "def load_pdf(file_path: str) -> List[Document]:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    return loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "Field 'name' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/model-field-overridden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPydanticUserError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 2. Classifier Tool\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mDocumentClassifierTool\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseTool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocument_classifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mClassifies if a PDF document is likely digital or non-digital (scanned).\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data/Development/AIenv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:113\u001b[39m, in \u001b[36mModelMetaclass.__new__\u001b[39m\u001b[34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m config_wrapper = ConfigWrapper.for_model(bases, namespace, kwargs)\n\u001b[32m    112\u001b[39m namespace[\u001b[33m'\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m'\u001b[39m] = config_wrapper.config_dict\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m private_attributes = \u001b[43minspect_namespace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mignored_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_field_names\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m private_attributes \u001b[38;5;129;01mor\u001b[39;00m base_private_attributes:\n\u001b[32m    117\u001b[39m     original_model_post_init = get_model_post_init(namespace, bases)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data/Development/AIenv/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:440\u001b[39m, in \u001b[36minspect_namespace\u001b[39m\u001b[34m(namespace, ignored_types, base_class_vars, base_class_fields)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m var_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m raw_annotations:\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01min\u001b[39;00m base_class_fields:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    441\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m defined on a base class was overridden by a non-annotated attribute. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    442\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAll field definitions, including overrides, require a type annotation.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    443\u001b[39m             code=\u001b[33m'\u001b[39m\u001b[33mmodel-field-overridden\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    444\u001b[39m         )\n\u001b[32m    445\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, FieldInfo):\n\u001b[32m    446\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    447\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m requires a type annotation\u001b[39m\u001b[33m'\u001b[39m, code=\u001b[33m'\u001b[39m\u001b[33mmodel-field-missing-annotation\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    448\u001b[39m         )\n",
      "\u001b[31mPydanticUserError\u001b[39m: Field 'name' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/model-field-overridden"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 2. Classifier Tool\n",
    "# ------------------------------------------------------------------------------\n",
    "class DocumentClassifierTool(BaseTool):\n",
    "    name = \"document_classifier\"\n",
    "    description = \"Classifies if a PDF document is likely digital or non-digital (scanned).\"\n",
    "\n",
    "    def _run(self, file_path: str) -> str:\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                pdf_reader = PyPDF2.PdfReader(f)\n",
    "                for page_num in range(min(5, len(pdf_reader.pages))):  # Check first few pages\n",
    "                    page = pdf_reader.pages[page_num]\n",
    "                    if page.extract_text().strip():\n",
    "                        return \"digital\"\n",
    "            return \"non_digital\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error during classification: {e}\")\n",
    "            return \"unknown\"\n",
    "\n",
    "    async def _arun(self, file_path: str) -> str:\n",
    "        raise NotImplementedError(\"This tool does not support asynchronous execution.\")\n",
    "\n",
    "classifier_tool = DocumentClassifierTool()\n",
    "\n",
    "def classify_document(documents: List[Document]) -> str:\n",
    "    # For simplicity, let's assume we classify based on the first document's metadata (if available)\n",
    "    # A more robust approach would involve analyzing the content.\n",
    "    file_path = documents[0].metadata.get(\"source\")\n",
    "    if file_path:\n",
    "        return classifier_tool.run(file_path)\n",
    "    return \"unknown\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 3. OCR Tool (Tesseract)\n",
    "# ------------------------------------------------------------------------------\n",
    "class TesseractOCRTool(BaseTool):\n",
    "    name = \"tesseract_ocr\"\n",
    "    description = \"Extracts text from a non-digital PDF document using Tesseract OCR.\"\n",
    "\n",
    "    def _run(self, file_path: str) -> str:\n",
    "        try:\n",
    "            return tesseract.image_to_string(file_path) # Requires converting PDF to image first\n",
    "        except Exception as e:\n",
    "            return f\"Error during OCR: {e}\"\n",
    "\n",
    "    async def _arun(self, file_path: str) -> str:\n",
    "        raise NotImplementedError(\"This tool does not support asynchronous execution.\")\n",
    "\n",
    "ocr_tool = TesseractOCRTool()\n",
    "\n",
    "def extract_text_ocr(documents: List[Document]) -> str:\n",
    "    file_path = documents[0].metadata.get(\"source\")\n",
    "    if file_path:\n",
    "        # Need to convert PDF pages to images for Tesseract\n",
    "        try:\n",
    "            from pdf2image import convert_from_path\n",
    "            images = convert_from_path(file_path)\n",
    "            full_text = \"\"\n",
    "            for img in images:\n",
    "                full_text += ocr_tool.run(img) + \"\\n\\n\"\n",
    "            return full_text.strip()\n",
    "        except ImportError:\n",
    "            return \"Error: pdf2image library not installed. Please install it (pip install pdf2image).\"\n",
    "        except Exception as e:\n",
    "            return f\"Error during PDF to image conversion or OCR: {e}\"\n",
    "    return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 4. PDF to Text Tool (Python Library - pdfminer.six)\n",
    "# ------------------------------------------------------------------------------\n",
    "def extract_text_digital(documents: List[Document]) -> str:\n",
    "    file_path = documents[0].metadata.get(\"source\")\n",
    "    if file_path:\n",
    "        try:\n",
    "            return pdfminer_extract_text(file_path)\n",
    "        except Exception as e:\n",
    "            return f\"Error during digital PDF text extraction: {e}\"\n",
    "    return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 5. Extraction Tool (OpenAI)\n",
    "# ------------------------------------------------------------------------------\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "extraction_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            \"You are an expert at extracting general details from documents.\"\n",
    "        ),\n",
    "        (\"user\", \"Extract key information from the following text: {text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "extraction_chain = extraction_prompt | llm\n",
    "\n",
    "def extract_details(text: str) -> str:\n",
    "    return extraction_chain.invoke({\"text\": text}).content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TypedDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mextracted_information\u001b[39m\u001b[33m\"\u001b[39m: extracted_details}\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Langgraph State Definition\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mGraphState\u001b[39;00m(\u001b[43mTypedDict\u001b[49m):\n\u001b[32m     11\u001b[39m     documents: List[Document]\n\u001b[32m     12\u001b[39m     classification: \u001b[38;5;28mstr\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'TypedDict' is not defined"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 6. Final Response\n",
    "# ------------------------------------------------------------------------------\n",
    "def format_response(extracted_details: str) -> Dict[str, str]:\n",
    "    return {\"extracted_information\": extracted_details}\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Langgraph State Definition\n",
    "# ------------------------------------------------------------------------------\n",
    "class GraphState(TypedDict):\n",
    "    documents: List[Document]\n",
    "    classification: str\n",
    "    extracted_text: str\n",
    "    extracted_details: str\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Langgraph Workflow Definition\n",
    "# ------------------------------------------------------------------------------\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# Load the document\n",
    "builder.add_node(\"load_document\", RunnableLambda(load_pdf))\n",
    "\n",
    "# Classify the document\n",
    "builder.add_node(\"classify\", RunnableLambda(classify_document))\n",
    "\n",
    "# Extract text for non-digital documents (OCR)\n",
    "builder.add_node(\"extract_text_ocr\", RunnableLambda(extract_text_ocr))\n",
    "\n",
    "# Extract text for digital documents\n",
    "builder.add_node(\"extract_text_digital\", RunnableLambda(extract_text_digital))\n",
    "\n",
    "# Extract general details using OpenAI\n",
    "builder.add_node(\"extract_details\", RunnableLambda(extract_details))\n",
    "\n",
    "# Format the final response\n",
    "builder.add_node(\"format_response\", RunnableLambda(format_response))\n",
    "\n",
    "# Define edges\n",
    "builder.set_entry_point(\"load_document\")\n",
    "\n",
    "builder.add_edge(\"load_document\", \"classify\")\n",
    "\n",
    "# Conditional routing based on classification\n",
    "def should_use_ocr(state):\n",
    "    return state[\"classification\"] == \"non_digital\"\n",
    "\n",
    "def should_use_digital_extraction(state):\n",
    "    return state[\"classification\"] == \"digital\"\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"classify\",\n",
    "    {\n",
    "        \"non_digital\": \"extract_text_ocr\",\n",
    "        \"digital\": \"extract_text_digital\",\n",
    "        \"unknown\": \"extract_text_digital\", # Default to digital if unknown\n",
    "    },\n",
    "    should_use_ocr,\n",
    ")\n",
    "\n",
    "builder.add_edge(\"extract_text_ocr\", \"extract_details\")\n",
    "builder.add_edge(\"extract_text_digital\", \"extract_details\")\n",
    "builder.add_edge(\"extract_details\", \"format_response\")\n",
    "builder.add_edge(\"format_response\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Example Usage\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a dummy digital PDF file for testing\n",
    "    with open(\"digital_document.pdf\", \"w\") as f:\n",
    "        f.write(\"This is a sample digital PDF document.\\nIt contains some text.\")\n",
    "\n",
    "    # Create a dummy non-digital PDF file (you'd typically have an actual scanned PDF)\n",
    "    # For this example, we'll just point to an image file that Tesseract can process.\n",
    "    # You'll need to have Tesseract installed and configured.\n",
    "    # You might need to manually create a simple image file (e.g., a screenshot) named \"scanned_document.png\"\n",
    "    # and then \"convert\" it to a single-page PDF named \"non_digital_document.pdf\".\n",
    "    # Example using ImageMagick (command line): `convert scanned_document.png non_digital_document.pdf`\n",
    "    if not os.path.exists(\"non_digital_document.pdf\"):\n",
    "        print(\"Please create a 'non_digital_document.pdf' (e.g., from a scanned image) for full testing.\")\n",
    "\n",
    "    # Test with a digital document\n",
    "    print(\"--- Processing Digital Document ---\")\n",
    "    result_digital = graph.invoke({\"documents\": [{\"metadata\": {\"source\": \"digital_document.pdf\"}}]})\n",
    "    print(result_digital)\n",
    "\n",
    "    # Test with a non-digital document (if the file exists)\n",
    "    if os.path.exists(\"non_digital_document.pdf\"):\n",
    "        print(\"\\n--- Processing Non-Digital Document ---\")\n",
    "        result_non_digital = graph.invoke({\"documents\": [{\"metadata\": {\"source\": \"non_digital_document.pdf\"}}]})\n",
    "        print(result_non_digital)\n",
    "    else:\n",
    "        print(\"\\nSkipping non-digital document test as 'non_digital_document.pdf' was not found.\")\n",
    "\n",
    "    # Clean up dummy files\n",
    "    os.remove(\"digital_document.pdf\")\n",
    "    if os.path.exists(\"non_digital_document.pdf\"):\n",
    "        # Be cautious about deleting actual scanned documents\n",
    "        pass # os.remove(\"non_digital_document.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
